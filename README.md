# Self-Driving-Rover
Autonomous self driving rover built for a simulated Mars environment using computer vision and YOLOv8. Detects and classifies objects such as tennis balls, hammers, balloons, and traffic cones, enabling real time navigation and obstacle avoidance through AI powered vision control.

This project was developed through a collaboration between students in Electrical Engineering, Mechanical Engineering, Control Systems, and Artificial Intelligence. The main objective was to design a self driving rover capable of navigating autonomously in a simulated Martian environment using computer vision and deep learning techniques.
As part of the AI team, my responsibility was to build the computer vision system that allows the rover to detect, classify, and respond to surrounding objects in real time. The objects of interest included a tennis ball, hammer, balloons in white, black, pink, and red, and a traffic cone. To prepare the data, I collected images of these objects through web scraping and uploaded them to Roboflow for annotation and augmentation. Roboflowâ€™s integration with Google Colab through an API made it easy to access and preprocess the dataset for model training. Data augmentation was performed using Albumentations to enhance diversity and balance class representation before splitting the dataset into training, validation, and testing subsets.
The object detection model was developed using YOLOv8 in combination with OpenCV and Albumentations. The model was trained for 100 epochs with an image size of 640 by 640 and early stopping to prevent overfitting. The training pipeline included data balancing, augmentation, and performance validation to ensure accurate detection across all object categories.
Once the model achieved satisfactory accuracy, I developed a Python script to enable real time object detection, balloon colour recognition, and position estimation within the frame. This detection system was then integrated into the roverâ€™s control module, allowing it to make movement decisions autonomously based on the detected objects and their positions.
The integration of deep learning, image processing, and control systems resulted in a fully functional self driving rover capable of identifying and avoiding obstacles with minimal human input. A short demonstration video showing the rover in motion is included in the repository.

ðŸŽ¥ [Watch Demo Video] (https://drive.google.com/file/d/1LzXfM4y5yb-d5GQFcEnEXXBR2UCmljrS/view?usp=share_link)
